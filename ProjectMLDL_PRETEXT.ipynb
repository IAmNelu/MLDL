{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectMLDL_PRETEXT_V8.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HK6Y0PKJ408U"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAmNelu/MLDL/blob/master/ProjectMLDL_PRETEXT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyFjPFtlrK0Y",
        "colab_type": "text"
      },
      "source": [
        "# Domain Adaptation Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC1sqv5BrG3R",
        "colab_type": "text"
      },
      "source": [
        "##Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGUUe-iZrQCQ",
        "colab_type": "text"
      },
      "source": [
        "Run Mount Drive then Copy 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzclAdrgr-Bn",
        "colab_type": "text"
      },
      "source": [
        "Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9OwuPWSlt-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  from google.colab import drive\n",
        "#  drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62iMqhIUrZJv",
        "colab_type": "text"
      },
      "source": [
        "Copy 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a4vHHzI8Kti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip /content/drive/My\\ Drive/synROD.zip -d /content/\n",
        "# !unzip /content/drive/My\\ Drive/ROD.zip -d /content/\n",
        "# !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1U0WobVS9A36UVEMcEK4YISHRqeDvFW78' -O rod-split_sync.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V45I_smbkFy5",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1QtntN8kou6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import functional as F\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torchvision.models import resnet18\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Function\n",
        "from torchvision import transforms\n",
        "from torch.backends import cudnn\n",
        "import torch.nn.functional as Fu\n",
        "from scipy import stats\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "import numbers\n",
        "import logging\n",
        "import os.path\n",
        "import random\n",
        "import torch\n",
        "import errno\n",
        "import copy\n",
        "import time\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axkn6Lm7sgl6",
        "colab_type": "text"
      },
      "source": [
        "##Functions & Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txZDH-EJkM7d",
        "colab_type": "text"
      },
      "source": [
        "###Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqbrnEbn6oHY",
        "colab_type": "text"
      },
      "source": [
        "####Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCBaAFs-nI_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pil_loader(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    img = Image.open(f)\n",
        "    return img.convert('RGB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj736EeK6eYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate_image(image, t1, t2, t3, transform):\n",
        "\n",
        "  rotation = random.randint(0,3)\n",
        "  if rotation == 0:\n",
        "    image = transform(image)\n",
        "    return image, rotation\n",
        "\n",
        "  elif rotation == 1: #90°\n",
        "    image_rotate = t3(image)\n",
        "    image_rotate = transform(image_rotate)\n",
        "    return image_rotate, rotation\n",
        "\n",
        "  elif rotation == 2: #180°\n",
        "    image_rotate = t2(image)\n",
        "    image_rotate = transform(image_rotate)\n",
        "    return image_rotate, rotation\n",
        "\n",
        "  elif rotation == 3: #270°\n",
        "    image_rotate = t1(image)\n",
        "    image_rotate = transform(image_rotate)\n",
        "    return image_rotate, rotation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz6lf7Fe6NfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_dictionary(path_file, ROD=False):\n",
        "  dictionary = {}\n",
        "  reverse_dictionary = {}\n",
        "  f = open(path_file, \"r\")\n",
        "  \n",
        "  for line in f:\n",
        "    path, label_index = line.split(\" \")\n",
        "    if ROD == False:\n",
        "      label_name = path.split(\"/\")[0]\n",
        "    else:\n",
        "      label_name = path.split(\"/\")[1]\n",
        "\n",
        "    dictionary[int(label_index)] = label_name\n",
        "    reverse_dictionary[label_name] = int(label_index)\n",
        "\n",
        "  return dictionary, reverse_dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQGI80zrkPvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_set(dataset, size=30000): #modify\n",
        "\n",
        "  dictionary = dataset.get_samples_label()\n",
        "  X = list(dictionary.keys())\n",
        "  y = list(dictionary.values())\n",
        "\n",
        "  indexes, _, _, _ = train_test_split(X, y, stratify=y, train_size=size)\n",
        "\n",
        "  return indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_ErRYQZ6xJh",
        "colab_type": "text"
      },
      "source": [
        "####ROD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oXZOXG2kPoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ROD(VisionDataset):\n",
        "  def __init__(self, root=None, file_path=None, validation=False, pretext=False, transform=None, target_transform=None):\n",
        "    super(ROD, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "\n",
        "    if file_path == None:\n",
        "      print(\"miss the path of the file!\")\n",
        "\n",
        "    if root == None:\n",
        "      print(\"miss the path of the dataset!\")\n",
        "      \n",
        "    #rotation\n",
        "    self.t1 = transforms.RandomRotation(degrees=[90, 90])\n",
        "    self.t2 = transforms.RandomRotation(degrees=[180, 180])\n",
        "    self.t3 = transforms.RandomRotation(degrees=[270, 270])\n",
        "  \n",
        "    self.samples_rgb = {}    #dictionary image_index -> path of the image\n",
        "    self.samples_depth = {}  #dictionary image_index -> path of the image\n",
        "    self.samples_label = {}  #dictionary image_index -> index of the label\n",
        "    self.labels_index = {}   #dictionary label_index -> name of the label\n",
        "    self.labels_name = {}    #dictionary label_names -> index of the label\n",
        "\n",
        "    self.labels_index, self.labels_name = initialize_dictionary(file_path, ROD=True) \n",
        "    self.pretext = pretext\n",
        "    self.validation = validation\n",
        "\n",
        "\n",
        "    # Read files and load images in memory  \n",
        "    idx = 0       #actual number of image\n",
        "    f = open(file_path, \"r\")\n",
        "    for line in f:\n",
        "      path, label = line.split(\" \")\n",
        "\n",
        "      rgb_path = path.replace(\"???\",\"rgb\",1)\n",
        "      rgb_path = rgb_path.replace(\"***\",\"crop\",1)\n",
        "      self.samples_rgb[idx] = pil_loader(root+\"/\"+rgb_path)\n",
        "\n",
        "      depth_path = path.replace(\"???\",\"surfnorm\",1)\n",
        "      depth_path = depth_path.replace(\"***\",\"depthcrop\",1)\n",
        "      self.samples_depth[idx] = pil_loader(root+\"/\"+depth_path)\n",
        "\n",
        "      self.samples_label[idx] = int(label)\n",
        "      idx += 1\n",
        "\n",
        "   \n",
        "  def __getitem__(self, index):\n",
        "    image_rgb = self.samples_rgb.get(index)\n",
        "    image_depth = self.samples_depth.get(index)\n",
        "\n",
        "    if self.validation: # if validation is true, target transformations are applied\n",
        "      image_rgb = self.target_transform(image_rgb)\n",
        "      image_depth = self.target_transform(image_depth)\n",
        "\n",
        "      label = self.samples_label.get(index)\n",
        "      return [image_rgb, image_depth], label\n",
        "\n",
        "    image_rgb = self.transform[0](image_rgb) #resize\n",
        "    image_depth = self.transform[0](image_depth)\n",
        "\n",
        "    image_rgb, image_depth = self.transform[1][0](image_rgb, image_depth) # Random Crop\n",
        "    image_rgb, image_depth = self.transform[1][1](image_rgb, image_depth) # Horizontal flip\n",
        "\n",
        "    if not self.pretext: \n",
        "      image_rgb = self.transform[2](image_rgb) # To Tensor & Normlize \n",
        "      image_depth = self.transform[2](image_depth)\n",
        "\n",
        "      label = self.samples_label.get(index)\n",
        "      \n",
        "      return [image_rgb, image_depth], label\n",
        "\n",
        "    else: # rotate the image\n",
        "      image_rgb, rotation_rgb = rotate_image(image_rgb, self.t1, self.t2, self.t3, self.transform[2]) #Rotation RGB\n",
        "      image_depth, rotation_depth = rotate_image(image_depth, self.t1, self.t2, self.t3, self.transform[2]) #Rotation Depth\n",
        "      \n",
        "      if rotation_rgb > rotation_depth:  # encoding relative rotation from rgb to depth\n",
        "        relative_rotation = 4 - rotation_rgb + rotation_depth\n",
        "      elif rotation_rgb < rotation_depth:\n",
        "        relative_rotation = rotation_depth - rotation_rgb\n",
        "      else:\n",
        "        relative_rotation = 0  \n",
        "\n",
        "      return [image_rgb, image_depth], relative_rotation\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    length = len(self.samples_rgb)\n",
        "    return length \n",
        "\n",
        "  def get_labels_dictionary(self):\n",
        "    return self.labels_index, self.labels_name\n",
        "\n",
        "  def get_samples_label(self):\n",
        "    return self.samples_label\n",
        "\n",
        "  def set_pretext(self, pretext):\n",
        "    self.pretext = pretext\n",
        "\n",
        "  def set_validation(self, validation):\n",
        "    self.validation = validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyOflxp96zhZ",
        "colab_type": "text"
      },
      "source": [
        "####synROD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn7MCiZJ63zZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class synROD(VisionDataset): \n",
        "  def __init__(self, root=None, file_path=None, pretext=False, transform=None, target_transform=None):\n",
        "    super(synROD, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "\n",
        "    if file_path == None:\n",
        "      print(\"miss the path of the file!\")\n",
        "\n",
        "    if root == None:\n",
        "      print(\"miss the path of the dataset!\")\n",
        "    \n",
        "    #rotation\n",
        "    self.t1 = transforms.RandomRotation(degrees=[90, 90])\n",
        "    self.t2 = transforms.RandomRotation(degrees=[180, 180])\n",
        "    self.t3 = transforms.RandomRotation(degrees=[270, 270])\n",
        "  \n",
        "    self.samples_rgb = {}    #dictionary image_index -> path of the image\n",
        "    self.samples_depth = {}  #dictionary image_index -> path of the image\n",
        "    self.samples_label = {}  #dictionary image_index -> index of the label\n",
        "    self.labels_index = {}   #dictionary label_index -> name of the label\n",
        "    self.labels_name = {}    #dictionary label_names -> index of the label\n",
        "\n",
        "    self.labels_index, self.labels_name = initialize_dictionary(file_path)\n",
        " \n",
        "    self.pretext = pretext\n",
        "    \n",
        "    # Read files and load path in memory  \n",
        "    idx = 0                  #actual number of images   \n",
        "    f = open(file_path, \"r\")\n",
        "\n",
        "    for line in f:\n",
        "      path, label = line.split(\" \")\n",
        "      \n",
        "      rgb_path = path.replace(\"***\",\"rgb\",1)\n",
        "      self.samples_rgb[idx] = root+\"/\"+rgb_path\n",
        "      \n",
        "      depth_path = path.replace(\"***\",\"depth\",1)\n",
        "      self.samples_depth[idx] = root+\"/\"+depth_path\n",
        "\n",
        "      self.samples_label[idx] = int(label)\n",
        "      idx += 1\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    path_rgb = self.samples_rgb.get(index)\n",
        "    image_rgb = pil_loader(path_rgb)            #load image\n",
        "    image_rgb = self.transform[0](image_rgb)    #resize image\n",
        "\n",
        "    path_depth = self.samples_depth.get(index)\n",
        "    image_depth = pil_loader(path_depth)\n",
        "    image_depth = self.transform[0](image_depth)\n",
        "\n",
        "    image_rgb, image_depth = self.transform[1][0](image_rgb, image_depth) # Random Crop\n",
        "    image_rgb, image_depth = self.transform[1][1](image_rgb, image_depth) # Horizontal flip\n",
        "\n",
        "    if not self.pretext:\n",
        "      image_rgb = self.transform[2](image_rgb)  #to tensor and normalize\n",
        "      image_depth = self.transform[2](image_depth)\n",
        "\n",
        "      label = self.samples_label.get(index)\n",
        "      \n",
        "      return [image_rgb, image_depth], label\n",
        "\n",
        "    else:\n",
        "      image_rgb, rotation_rgb = rotate_image(image_rgb, self.t1, self.t2, self.t3, self.transform[2])\n",
        "      image_depth, rotation_depth = rotate_image(image_depth, self.t1, self.t2, self.t3, self.transform[2])\n",
        "\n",
        "      if rotation_rgb > rotation_depth:  # encoding relative rotation from rgb to depth\n",
        "        relative_rotation = 4 - rotation_rgb + rotation_depth\n",
        "      elif rotation_rgb < rotation_depth:\n",
        "        relative_rotation = rotation_depth - rotation_rgb\n",
        "      else:\n",
        "        relative_rotation = 0  \n",
        "\n",
        "      return [image_rgb, image_depth], relative_rotation\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    length = len(self.samples_rgb)\n",
        "    return length \n",
        "\n",
        "  def get_labels_dictionary(self):\n",
        "    return self.labels_index, self.labels_name\n",
        "\n",
        "  def get_samples_label(self):\n",
        "    return self.samples_label\n",
        "\n",
        "  def set_pretext(self, pretext):\n",
        "    self.pretext = pretext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5trOPX1TtDSH",
        "colab_type": "text"
      },
      "source": [
        "### Network "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgi_YjTuw8hy",
        "colab_type": "text"
      },
      "source": [
        "####Helping Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aLqenSww8Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "  \"\"\"3x3 convolution with padding\"\"\"\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                   padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "  \"\"\"1x1 convolution\"\"\"\n",
        "  return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "               base_width=64, dilation=1, norm_layer=None):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    if norm_layer is None:\n",
        "      norm_layer = nn.BatchNorm2d\n",
        "    if groups != 1 or base_width != 64:\n",
        "      raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "    if dilation > 1:\n",
        "      raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "    # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "    self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "    self.bn1 = norm_layer(planes)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.conv2 = conv3x3(planes, planes)\n",
        "    self.bn2 = norm_layer(planes)\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    if self.downsample is not None:\n",
        "      identity = self.downsample(x)\n",
        "\n",
        "    out += identity\n",
        "    out = self.relu(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK6Y0PKJ408U",
        "colab_type": "text"
      },
      "source": [
        "####MagicNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCNPfRV29VC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MagicNet(nn.Module):\n",
        "\n",
        "  def __init__(self, block, layers, complete=True, num_classes=1000, zero_init_residual=False,\n",
        "                groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                norm_layer=None):\n",
        "    super(MagicNet, self).__init__()\n",
        "    if norm_layer is None:\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "    self._norm_layer = norm_layer\n",
        "\n",
        "    self.complete = complete\n",
        "    self.inplanes = 64\n",
        "    self.dilation = 1\n",
        "    if replace_stride_with_dilation is None:\n",
        "        # each element in the tuple indicates if we should replace\n",
        "        # the 2x2 stride with a dilated convolution instead\n",
        "        replace_stride_with_dilation = [False, False, False]\n",
        "    if len(replace_stride_with_dilation) != 3:\n",
        "        raise ValueError(\"replace_stride_with_dilation should be None or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "    self.groups = groups\n",
        "    self.base_width = width_per_group\n",
        "    # CODA Ec\n",
        "    # First layer 7x7, 64 neurons stride 2\n",
        "    self.conv1_c = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1_c = norm_layer(self.inplanes)\n",
        "    self.relu_c = nn.ReLU(inplace=True)\n",
        "    self.maxpool_c = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.layer1_c = self._make_layer(block, 64, layers[0])  \n",
        "    self.layer2_c = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])  \n",
        "    self.layer3_c = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])  \n",
        "    self.layer4_c = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])  \n",
        "    self.inplanes = 64  # reset inplanes number\n",
        "    # CODA Ed\n",
        "    # First layer 7x7, 64 neurons stride 2\n",
        "    self.conv1_d = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1_d = norm_layer(self.inplanes)\n",
        "    self.relu_d = nn.ReLU(inplace=True)\n",
        "    self.maxpool_d = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.layer1_d = self._make_layer(block, 64, layers[0])  \n",
        "    self.layer2_d = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])  \n",
        "    self.layer3_d = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])  \n",
        "    self.layer4_d = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])  \n",
        "\n",
        "    multiplier = 1\n",
        "    if  complete:\n",
        "      multiplier = 2\n",
        "    \n",
        "    # Head M\n",
        "    self.main_head = nn.Sequential(OrderedDict([\n",
        "        ('avgpool_m',   nn.AdaptiveAvgPool2d((1, 1))), # https://discuss.pytorch.org/t/adaptive-avg-pool2d-vs-avg-pool2d/27011\n",
        "        ('flatten',     nn.Flatten(1)),\n",
        "        ('fc_m1000',    nn.Linear(512 * block.expansion * multiplier, 1000)),# multiplied by 2: 512 for RGB and 512 for depth\n",
        "        ('normal_m',    nn.BatchNorm1d(1000)),\n",
        "        ('relu_mfc',    nn.ReLU(inplace=True)),\n",
        "        ('drop_m1000',  nn.Dropout()),\n",
        "        ('fc_mC',       nn.Linear(1000, num_classes)),\n",
        "    ]))\n",
        "\n",
        "\n",
        "    # Head P\n",
        "    self.pretext_head = nn.Sequential(OrderedDict([\n",
        "        ('conv1_p',     nn.Conv2d(512*multiplier, 100, kernel_size=1,stride=1)),\n",
        "        ('normal_pcv1', nn.BatchNorm2d(100)),\n",
        "        ('relu_pc1',    nn.ReLU(inplace=True)),\n",
        "        ('conv2_p',     nn.Conv2d(100, 100, kernel_size=3,stride=2)),\n",
        "        ('normal_pcv2', nn.BatchNorm2d(100)),\n",
        "        ('relu_pc2',    nn.ReLU(inplace=True)),\n",
        "        ('flatten',     nn.Flatten(1)),\n",
        "        ('fc_p100',     nn.Linear(900, 100)),\n",
        "        ('normal_pfc',  nn.BatchNorm1d(100)),\n",
        "        ('relu_pfc',    nn.ReLU(inplace=True)),\n",
        "        ('drop_p100',   nn.Dropout()),\n",
        "        ('fc_p4',       nn.Linear(100, 4)),\n",
        "    ]))\n",
        "\n",
        "  def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "    norm_layer = self._norm_layer\n",
        "    downsample = None\n",
        "    previous_dilation = self.dilation\n",
        "    if dilate:\n",
        "      self.dilation *= stride\n",
        "      stride = 1\n",
        "    if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "      downsample = nn.Sequential(\n",
        "          conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "          norm_layer(planes * block.expansion),\n",
        "      )\n",
        "\n",
        "    layers = []\n",
        "    layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                        self.base_width, previous_dilation, norm_layer))\n",
        "    self.inplanes = planes * block.expansion\n",
        "    for _ in range(1, blocks):\n",
        "      layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                          base_width=self.base_width, dilation=self.dilation,\n",
        "                          norm_layer=norm_layer))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def _forward_impl(self, rgb_x=None, dp_x=None, main_task=True): \n",
        "    \n",
        "    rgb_x = self.conv1_c(rgb_x)\n",
        "    rgb_x = self.bn1_c(rgb_x)\n",
        "    rgb_x = self.relu_c(rgb_x)\n",
        "    rgb_x = self.maxpool_c(rgb_x)\n",
        "\n",
        "    rgb_x = self.layer1_c(rgb_x)\n",
        "    rgb_x = self.layer2_c(rgb_x)\n",
        "    rgb_x = self.layer3_c(rgb_x)\n",
        "    rgb_x = self.layer4_c(rgb_x)\n",
        "\n",
        "\n",
        "    dp_x = self.conv1_d(dp_x)\n",
        "    dp_x = self.bn1_d(dp_x)\n",
        "    dp_x = self.relu_d(dp_x)\n",
        "    dp_x = self.maxpool_d(dp_x)\n",
        "\n",
        "    dp_x = self.layer1_d(dp_x)\n",
        "    dp_x = self.layer2_d(dp_x)\n",
        "    dp_x = self.layer3_d(dp_x)\n",
        "    dp_x = self.layer4_d(dp_x)\n",
        "\n",
        "    d_rgb_x = torch.cat((dp_x, rgb_x), 1)  #concatenation\n",
        "\n",
        "    if main_task:\n",
        "      d_rgb_x = self.main_head(d_rgb_x)\n",
        "    else:\n",
        "      d_rgb_x = self.pretext_head(d_rgb_x)\n",
        "    return d_rgb_x\n",
        "\n",
        "  def forward(self, rgb_x=None, dp_x=None, main_task=True):\n",
        "    return self._forward_impl(rgb_x=rgb_x, dp_x=dp_x, main_task=main_task)\n",
        "\n",
        "  def initNet(self):\n",
        "    netSource = resnet18(pretrained=True)\n",
        "    # copy Ec\n",
        "    self.conv1_c.weight.data = copy.deepcopy(netSource.conv1.weight.data)\n",
        "    self.bn1_c.weight.data = copy.deepcopy(netSource.bn1.weight.data)\n",
        "    self.bn1_c.bias.data = copy.deepcopy(netSource.bn1.bias.data)\n",
        "    self.bn1_c.running_mean.data = copy.deepcopy(netSource.bn1.running_mean.data)\n",
        "    self.bn1_c.running_var.data = copy.deepcopy(netSource.bn1.running_var.data)\n",
        "    self.layer1_c = copy.deepcopy(netSource.layer1)\n",
        "    self.layer2_c = copy.deepcopy(netSource.layer2)\n",
        "    self.layer3_c = copy.deepcopy(netSource.layer3)\n",
        "    self.layer4_c = copy.deepcopy(netSource.layer4)\n",
        "    # copy Ed\n",
        "    self.conv1_d.weight.data = copy.deepcopy(netSource.conv1.weight.data)\n",
        "    self.bn1_d.weight.data = copy.deepcopy(netSource.bn1.weight.data)\n",
        "    self.bn1_d.bias.data = copy.deepcopy(netSource.bn1.bias.data)\n",
        "    self.bn1_d.running_mean.data = copy.deepcopy(netSource.bn1.running_mean.data)\n",
        "    self.bn1_d.running_var.data = copy.deepcopy(netSource.bn1.running_var.data)\n",
        "    self.layer1_d = copy.deepcopy(netSource.layer1)\n",
        "    self.layer2_d = copy.deepcopy(netSource.layer2)\n",
        "    self.layer3_d = copy.deepcopy(netSource.layer3)\n",
        "    self.layer4_d = copy.deepcopy(netSource.layer4)\n",
        "\n",
        "    for module in self.main_head:\n",
        "      if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "        nn.init.xavier_uniform_(module.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        if not module.bias.data is None:\n",
        "            module.bias.data.zero_()\n",
        "    for module in self.pretext_head:\n",
        "      if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "        nn.init.xavier_uniform_(module.weight.data, gain=nn.init.calculate_gain('relu'))\n",
        "        if not module.bias.data is None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "  def load_state_from_file(self, file_name):\n",
        "    if os.path.isfile(file_name):\n",
        "      self.load_state_dict(torch.load(file_name))\n",
        "      print(f'Model {file_name} loaded succesfully')\n",
        "    else:\n",
        "      raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), file_name)\n",
        "\n",
        "  def save_state_on_file(self, file_name):\n",
        "    torch.save(self.state_dict(), file_name)\n",
        "    print(f'Model saved succesfully on file {file_name}')\n",
        "      \n",
        "def _magicnet(block, pretrained, complete, **kwargs):\n",
        "  model = MagicNet(block, [2, 2, 2, 2], complete=complete, **kwargs)\n",
        "  if pretrained:\n",
        "    if os.path.isfile('magic_net.pth'):\n",
        "      model.load_state_dict(torch.load(\"magic_net.pth\"))\n",
        "    else:\n",
        "      model.initNet()\n",
        "      torch.save(model.state_dict(), 'magic_net.pth')\n",
        "  return model\n",
        "\n",
        "\n",
        "def magicnet(pretrained=False, complete=True, **kwargs): # Complete uses both rgb and depth\n",
        "  return _magicnet(BasicBlock, pretrained, complete=complete, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfla0S2U1jZn",
        "colab_type": "text"
      },
      "source": [
        "###Utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVJiaVTTlC9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def entropy_loss(logits):\n",
        "  p_softmax = Fu.softmax(logits, dim=1)\n",
        "  mask = p_softmax.ge(0.000001)  # greater or equal to, used for numerical stability\n",
        "  mask_out = torch.masked_select(p_softmax, mask)\n",
        "  entropy = -(torch.sum(mask_out * torch.log(mask_out)))\n",
        "  return entropy / float(p_softmax.size(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTD1wCeyyBAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getTimes(start_s, end_s, for_what='test'):\n",
        "  time_taken = end_s - start_s\n",
        "  seconds = int(time_taken%60)\n",
        "  time_taken -= seconds\n",
        "  minutes = int(time_taken/60)\n",
        "  ores = int(minutes/60)\n",
        "  minutes %= 60\n",
        "  minutes = int(minutes)\n",
        "  ores_s = str(ores)\n",
        "  minutes_s = str(minutes)\n",
        "  seconds_s = str(seconds)\n",
        "  if ores < 10:\n",
        "    ores_s = '0' + ores_s\n",
        "  if minutes < 10:\n",
        "    minutes_s = '0' + minutes_s\n",
        "  if seconds < 10:\n",
        "    seconds_s = '0' + seconds_s\n",
        "  print(f'Time taken for {for_what}: {ores_s}:{minutes_s}:{seconds_s}')\n",
        "  return f'{ores_s}:{minutes_s}:{seconds_s}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5K39q3MaWlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_losses(losses, sampling_size=10, labels=['Main Task Loss', 'Entropy Loss ROD','synROD Pretext Task', 'ROD Pretext Task'], \n",
        "                colors=['#2AC213','#0A5DC2','#C23094','#C2810A'], fig_size=(10,7), \n",
        "                        legend_pos=(0.74,0.99), save_to_png=False, title='Loss', x_label='Step #', y_label='Loss'):\n",
        "  x = np.arange(len(losses[0]))\n",
        "  fig = plt.figure(figsize=fig_size)\n",
        "  ax = fig.add_subplot(111)\n",
        "  print(len(losses))\n",
        "  for i, y in enumerate(losses):\n",
        "    if len(y) > 0:\n",
        "      ax.plot(x[::sampling_size], y[::sampling_size], linestyle='-',  marker=\"h\", c=colors[i], label=labels[i])\n",
        "  ax.plot(x, [min(losses[0])]*len(losses[0]), c='r', linestyle='--',  marker=\"\", label=f'Min Loss {min(losses[0]):.2f}')\n",
        "  plt.legend(bbox_to_anchor=legend_pos, loc='upper left', borderaxespad=0.)\n",
        "  \n",
        "  plt.grid(color='w')\n",
        "  # plt.ylim(0)\n",
        "  ax.set_axisbelow(True)\n",
        "  ax.set_facecolor('#EAEAF2')\n",
        "  plt.xlabel(x_label)\n",
        "  plt.ylabel(y_label)\n",
        "  ax.yaxis.grid('Ture')\n",
        "  plt.title(title, fontsize=25)\n",
        "  if save_to_png:\n",
        "    plt.savefig(f\"{title}.png\", dpi=240)\n",
        "  else:\n",
        "    plt.show()\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFxKQCVx4_Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracies(accuracies, test_accuracy=None, sampling_size=1, \n",
        "                  labels=['Validation Accuracies', 'Test Accuracy'], \n",
        "                  colors=['#7C55BD','#42BD5B'], fig_size=(10,7), \n",
        "                          legend_pos=(0.74,0.99), save_to_png=False, \n",
        "                          title='Accuracies in %', x_label='Epochs', y_label='Accuracy'):\n",
        "  x = np.arange(len(accuracies))\n",
        "  fig = plt.figure(figsize=fig_size)\n",
        "  ax = fig.add_subplot(111)\n",
        "\n",
        "  ax.plot(x[::sampling_size], accuracies[::sampling_size], linestyle='-',  marker=\"h\", c=colors[0], label=labels[0])\n",
        "  if not test_accuracy is None:\n",
        "    ax.plot(x, [test_accuracy]*len(accuracies), c=colors[1], linestyle='-',  marker=\"\", label=labels[1])\n",
        "  ax.plot(x, [max(accuracies)]*len(accuracies), c='r', linestyle='--',  marker=\"\", label=f'Max Accuracy {max(accuracies):.2f}%')\n",
        "  plt.legend(bbox_to_anchor=legend_pos, loc='upper left', borderaxespad=0.)\n",
        "  \n",
        "  plt.grid(color='w')\n",
        "  # plt.ylim(0)\n",
        "  ax.set_axisbelow(True)\n",
        "  ax.set_facecolor('#EAEAF2')\n",
        "  plt.xlabel(x_label)\n",
        "  plt.ylabel(y_label)\n",
        "  ax.yaxis.grid('Ture')\n",
        "  plt.title(title, fontsize=25)\n",
        "  if save_to_png:\n",
        "    plt.savefig(f\"{title}.png\", dpi=240)\n",
        "  else:\n",
        "    plt.show()\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiXZ9mkGyFdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stop_trining_4(array_of_validations):\n",
        "  if len(array_of_validations) < 4:\n",
        "    return False\n",
        "  if array_of_validations[-1] < array_of_validations[-2] < array_of_validations[-3] < array_of_validations[-4]:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def stop_trining_3(array_of_validations):\n",
        "  if len(array_of_validations) < 3:\n",
        "    return False\n",
        "  if array_of_validations[-1] < array_of_validations[-2] < array_of_validations[-3]:\n",
        "    return True\n",
        "  return False\n",
        "  \n",
        "def stop_trining_2(array_of_validations):\n",
        "  if len(array_of_validations) < 2:\n",
        "    return False\n",
        "  if array_of_validations[-1] < array_of_validations[-2]:\n",
        "    return True\n",
        "  return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqJCoyIYK9bV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_list(filename):\n",
        "  if os.path.isfile(filename):\n",
        "    lista = []\n",
        "    with open(filename, 'r') as f:\n",
        "      for row in f:\n",
        "        lista.append(float(row))\n",
        "    return lista\n",
        "  else:\n",
        "    return []\n",
        "def write_list(filename, values):\n",
        "  with open(filename, 'a') as f:\n",
        "    for val in values:\n",
        "      f.write(f'{str(val)}\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igZAtIELgbaz",
        "colab_type": "text"
      },
      "source": [
        "###Validation / test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QxB7JhigaGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Validation\n",
        "def test_validate(net, valid_dataloader, len_data, DEVICE='cuda', padding_text='A'):\n",
        "  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "  running_corrects = 0\n",
        "  for images, labels in tqdm(valid_dataloader):\n",
        "    labels = labels.to(DEVICE)\n",
        "    #concatenate RGB and Depth for Syn\n",
        "    imagesRGB = images[0].to(DEVICE)\n",
        "    imagesD = images[1].to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    outputs = net(rgb_x=imagesRGB, dp_x=imagesD)\n",
        "    \n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len_data)\n",
        "\n",
        "  print(f'{padding_text}ccuracy: {accuracy*100:.2f}%')\n",
        "  net.train(True)\n",
        "  return accuracy * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwJmpWJWv-Xz",
        "colab_type": "text"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RevLG2iXwAqt",
        "colab_type": "text"
      },
      "source": [
        "###Prepare Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPfEKMXZwIEz",
        "colab_type": "text"
      },
      "source": [
        "#####Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqHuTIHva1aE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "\n",
        "NUM_CLASSES = 47 \n",
        "BATCH_SIZE = 32      \n",
        "LR = 3e-4            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 0.05\n",
        "NUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\n",
        "\n",
        "ALPHA = 1\n",
        "ENTROPY_LOSS_WEIGHT=0.1  #lambda\n",
        "LOG_FREQUENCY = 100\n",
        "VALIDATION_SIZE = BATCH_SIZE * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa3ocL7JwLiD",
        "colab_type": "text"
      },
      "source": [
        "####Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6gbsoqm8XXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomCrop(object):\n",
        "  def __init__(self, size, padding=None, pad_if_needed=False, fill=0, padding_mode='constant'):\n",
        "    if isinstance(size, numbers.Number):\n",
        "      self.size = (int(size), int(size))\n",
        "    else:\n",
        "      self.size = size\n",
        "    self.padding = padding\n",
        "    self.pad_if_needed = pad_if_needed\n",
        "    self.fill = fill\n",
        "    self.padding_mode = padding_mode\n",
        "\n",
        "  @staticmethod\n",
        "  def get_params(img, output_size):\n",
        "    w, h = img.size\n",
        "    th, tw = output_size\n",
        "    if w == tw and h == th:\n",
        "      return 0, 0, h, w\n",
        "\n",
        "    i = random.randint(0, h - th)\n",
        "    j = random.randint(0, w - tw)\n",
        "    return i, j, th, tw\n",
        "\n",
        "  def __call__(self, img1, img2):\n",
        "    \n",
        "    if self.padding is not None:\n",
        "      img1 = F.pad(img1, self.padding, self.fill, self.padding_mode)\n",
        "      img2 = F.pad(img2, self.padding, self.fill, self.padding_mode)\n",
        "\n",
        "    # pad the width if needed (img1)\n",
        "    if self.pad_if_needed and img1.size[0] < self.size[1]:\n",
        "      img1 = F.pad(img1, (self.size[1] - img1.size[0], 0), self.fill, self.padding_mode)\n",
        "\n",
        "    # pad the height if needed (img 1)\n",
        "    if self.pad_if_needed and img1.size[1] < self.size[0]:\n",
        "      img1 = F.pad(img1, (0, self.size[0] - img1.size[1]), self.fill, self.padding_mode)\n",
        "\n",
        "      # pad the width if needed (img 2)\n",
        "    if self.pad_if_needed and img2.size[0] < self.size[1]:\n",
        "      img2 = F.pad(img2, (self.size[1] - img2.size[0], 0), self.fill, self.padding_mode)\n",
        "\n",
        "    # pad the height if needed (img 2)\n",
        "    if self.pad_if_needed and img2.size[1] < self.size[0]:\n",
        "      img2 = F.pad(img2, (0, self.size[0] - img2.size[1]), self.fill, self.padding_mode)\n",
        "\n",
        "    i, j, h, w = self.get_params(img1, self.size)\n",
        "\n",
        "    return F.crop(img1, i, j, h, w), F.crop(img2, i, j, h, w)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.__class__.__name__ + '(size={0}, padding={1})'.format(self.size, self.padding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcFoAH4B8bm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomHorizontalFlip(object):\n",
        "  def __init__(self, p=0.5):\n",
        "    self.p = p\n",
        "\n",
        "  def __call__(self, img1, img2):\n",
        "    if random.random() < self.p:\n",
        "      return F.hflip(img1), F.hflip(img2)\n",
        "    return img1, img2\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.__class__.__name__ + '(p={})'.format(self.p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hybTo-p9kP2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set trasformation\n",
        "train_transform_resize = transforms.Resize(256)\n",
        "train_transform_pair_image = [RandomCrop(224), RandomHorizontalFlip()] \n",
        "train_transform_final = transforms.Compose([transforms.ToTensor(), \n",
        "                                            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOTy7k1EwSHE",
        "colab_type": "text"
      },
      "source": [
        "####Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDbI9gfmGicg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DIR_synROD =\"synROD\"\n",
        "DIR_ROD = \"ROD\"\n",
        "synROD_train_split = \"/content/synROD/synARID_50k-split_sync_train1.txt\"\n",
        "synROD_test_split = \"/content/synROD/synARID_50k-split_sync_test1.txt\"\n",
        "ROD_split = \"/content/rod-split_sync.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWex8yDo7PNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "synROD_train_dataset = synROD(DIR_synROD,transform=[train_transform_resize, train_transform_pair_image,train_transform_final], file_path=synROD_train_split)\n",
        "ROD_dataset = ROD(DIR_ROD,transform=[train_transform_resize, train_transform_pair_image,train_transform_final], target_transform=test_transform, file_path=ROD_split)\n",
        "\n",
        "print(f'synROD train Dataset: {len(synROD_train_dataset)}')\n",
        "print(f'ROD Dataset: {len(ROD_dataset)}')\n",
        "\n",
        "indexes = reduce_set(synROD_train_dataset, size=len(ROD_dataset))\n",
        "synROD_reduced_dataset = Subset(synROD_train_dataset, indexes)\n",
        "print(f'synROD Dataset: {len(synROD_reduced_dataset)}')\n",
        "\n",
        "indexes = reduce_set(ROD_dataset, size=VALIDATION_SIZE)\n",
        "ROD_validation_dataset = Subset(ROD_dataset, indexes)\n",
        "print(f'ROD validation Dataset: {VALIDATION_SIZE}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2bhrnX57TuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "synROD_dataloader = DataLoader(synROD_reduced_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "ROD_dataloader = DataLoader(ROD_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "ROD_dataloader_valid = DataLoader(ROD_validation_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "synROD_dataloader_r = DataLoader(synROD_reduced_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "ROD_dataloader_r = DataLoader(ROD_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUrks9_NkYMW",
        "colab_type": "text"
      },
      "source": [
        "#### Net & Loss & Optimizer & Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhLc9xJ3jMp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = magicnet(pretrained=True, num_classes=NUM_CLASSES)\n",
        "# Define loss function\n",
        "criterion_maintask = nn.CrossEntropyLoss()\n",
        "criterion_pretext_ROD = nn.CrossEntropyLoss()\n",
        "criterion_pretext_synROD = nn.CrossEntropyLoss()\n",
        "\n",
        "parameters_to_optimize = net.parameters() \n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1cRkdN78gPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reti = []\n",
        "ottimizzatori = []\n",
        "epochs_done = 0\n",
        "loss_syn_c_file = 'loss_syn_c.txt'\n",
        "loss_syn_p_file = 'loss_syn_p.txt'\n",
        "loss_rod_c_file = 'loss_rod_c.txt'\n",
        "loss_rod_p_file = 'loss_rod_p.txt'\n",
        "validations_file = 'validations.txt'\n",
        "for file_n in os.listdir():\n",
        "  if file_n.startswith('magic_ep_'):\n",
        "    reti.append(file_n)\n",
        "  elif file_n.startswith('optimizer_ep_'):\n",
        "    ottimizzatori.appendd(file_n)\n",
        "  elif file_n.startswith('loss_syn_c'):\n",
        "    loss_syn_c_file = file_n\n",
        "  elif file_n.startswith('loss_syn_p'):\n",
        "    loss_syn_p_file = file_n\n",
        "  elif file_n.startswith('loss_rod_c'):\n",
        "    loss_rod_c_file = file_n \n",
        "  elif file_n.startswith('loss_rod_p'):\n",
        "    loss_rod_p_file = file_n\n",
        "  elif file_n.startswith('validations'):\n",
        "    validations_file = file_n\n",
        "\n",
        "if len(reti) != 0:\n",
        "  epochs_done = int(reti[-1].split('magic_ep_')[-1].split('_')[0])\n",
        "  net.load_from_file(reti[-1])\n",
        "  optimizer.load_state_dict(torch.load(ottimizzatori[-1])['optimizer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qfXcFRQkcgy",
        "colab_type": "text"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krecsC99Jieb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "p_myloss_clas_syn = []\n",
        "p_myloss_pretext_syn = []\n",
        "p_myloss_clas_rod = []\n",
        "p_myloss_pretext_rod = []\n",
        "p_validations = read_list(validations_file)\n",
        "p_current_step = 0\n",
        "p_best_net = None\n",
        "best_val = 0\n",
        "effective_ep = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmOxkJwl1pYF",
        "colab_type": "text"
      },
      "source": [
        "#### Pretext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF1ik4AZ1uV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################## PRETEXT: Domain Adaptation \n",
        "# Start iterating over the epochs\n",
        "N_BATCH = len(ROD_dataloader)\n",
        "\n",
        "ask_for_money = time.time()\n",
        "for epoch in range(epochs_done, NUM_EPOCHS):\n",
        "  one_day_baby = time.time()\n",
        "  print(f'Starting epoch {epoch+1}/{NUM_EPOCHS}, LR = {LR}')\n",
        "\n",
        "  synROD_train_dataset.set_pretext(False)\n",
        "  ROD_dataset.set_pretext(False)\n",
        "  synROD_iter = iter(synROD_dataloader)\n",
        "  ROD_iter = iter(ROD_dataloader)\n",
        "\n",
        "  synROD_train_dataset.set_pretext(True)\n",
        "  ROD_dataset.set_pretext(True)\n",
        "  synROD_iter_r = iter(synROD_dataloader_r)\n",
        "  ROD_iter_r = iter(ROD_dataloader_r)\n",
        "  \n",
        "  for _ in range(N_BATCH):\n",
        "    net.train(True) # Sets module in training mode\n",
        "\n",
        "    if p_current_step % 2 == 0:\n",
        "      optimizer.zero_grad() # Zero-ing the gradients\n",
        "    \n",
        "    #MAIN TASK\n",
        "    #synROD\n",
        "    images, labels = next(synROD_iter)\n",
        "\n",
        "    #load on DEVICE label, images RGB and Depth\n",
        "    label = labels.to(DEVICE)\n",
        "    imageRGB = images[0].to(DEVICE) #RGB\n",
        "    imageD = images[1].to(DEVICE)   #Depth\n",
        "\n",
        "    # Forward pass to the network synROD\n",
        "    outputs = net(rgb_x=imageRGB, dp_x=imageD) #main_task=True\n",
        "    loss_main = criterion_maintask(outputs, label)\n",
        "    p_myloss_clas_syn.append(loss_main.item())\n",
        "    loss_main.backward(retain_graph=True) #retain_graph to be able to compute again the gradient\n",
        "      \n",
        "    #ROD\n",
        "    images, _ = next(ROD_iter)\n",
        "    #load on DEVICE images RGB and Depth\n",
        "    imageRGB = images[0].to(DEVICE)  #RGB\n",
        "    imageD = images[1].to(DEVICE)    #Depth\n",
        "\n",
        "    # Forward pass to the network ROD\n",
        "    outputs = net(rgb_x=imageRGB, dp_x=imageD) #main_task=True\n",
        "    loss_no_label = entropy_loss(outputs)\n",
        "    loss_no_label *= ENTROPY_LOSS_WEIGHT\n",
        "\n",
        "    p_myloss_clas_rod.append(loss_no_label.item()/ENTROPY_LOSS_WEIGHT)\n",
        "    loss_no_label.backward(retain_graph=True)\n",
        "        \n",
        "    #PRETEXT TASK: S and T rotated\n",
        "    #synROD\n",
        "    images, labels = next(synROD_iter_r)\n",
        "    #load on DEVICE labels, images RGB rotated and Depth rotated\n",
        "    label = labels.to(DEVICE)\n",
        "    imageRGB = images[0].to(DEVICE) #RGB\n",
        "    imageD = images[1].to(DEVICE)   #Depth\n",
        "\n",
        "    outputs = net(rgb_x=imageRGB, dp_x=imageD, main_task=False)\n",
        "\n",
        "    loss_pretext_synROD = criterion_pretext_synROD(outputs, label)\n",
        "    loss_pretext_synROD *= ALPHA\n",
        "    p_myloss_pretext_syn.append(loss_pretext_synROD.item())#/ALPHA)\n",
        "    loss_pretext_synROD.backward(retain_graph=True)\n",
        "    \n",
        "    #ROD\n",
        "    images, labels = next(ROD_iter_r)\n",
        "    #load on DEVICE labels, images RGB rotated and Depth rotated\n",
        "    label = labels.to(DEVICE)\n",
        "    imageRGB = images[0].to(DEVICE) #RGB\n",
        "    imageD = images[1].to(DEVICE)   #Depth\n",
        "\n",
        "    outputs = net(rgb_x=imageRGB, dp_x=imageD, main_task=False) \n",
        "\n",
        "    loss_pretext_ROD = criterion_pretext_ROD(outputs, label)\n",
        "    loss_pretext_ROD *= ALPHA\n",
        "    p_myloss_pretext_rod.append(loss_pretext_ROD.item())#/ALPHA)  \n",
        "    loss_pretext_ROD.backward(retain_graph=True)  \n",
        "    \n",
        "    #Clear Memory\n",
        "    label = None\n",
        "    imageRGB = None\n",
        "    imageD = None\n",
        "\n",
        "    if p_current_step % 2 == 1:\n",
        "      optimizer.step()\n",
        "\n",
        "    if p_current_step % LOG_FREQUENCY == 0:\n",
        "      print(f'-----------------STEP {p_current_step:6}-----------------')\n",
        "      print(f'|{\"SYN CLASS\":10}|{\"ROD CLASS\":10}|{\"PRE S\":10}|{\"PRE T\":10}|')\n",
        "      print(f'|{loss_main.item():10.4f}|{loss_no_label.item()/ENTROPY_LOSS_WEIGHT:10.4f}|{loss_pretext_synROD.item()/ALPHA:10.4f}|{loss_pretext_ROD.item()/ALPHA:10.4f}|')\n",
        "      #print(f'---------------------------------------------')\n",
        "    p_current_step += 1\n",
        "\n",
        "  ROD_dataset.set_validation(True)\n",
        "  valid_value = test_validate(net, ROD_dataloader_valid, VALIDATION_SIZE, DEVICE)\n",
        "  ROD_dataset.set_validation(False)\n",
        "\n",
        "  if valid_value > best_val:\n",
        "    best_val = valid_value\n",
        "    p_best_net = copy.deepcopy(net)\n",
        "  p_validations.append(valid_value)\n",
        "\n",
        "  will_be_old_oh_baby = time.time()\n",
        "  time_ep = getTimes(one_day_baby, will_be_old_oh_baby, 'one EPOCH')\n",
        "  # Save States\n",
        "  valid_value_s = f'{valid_value:.2f}'\n",
        "  valid_value_s = valid_value_s.replace('.', '_')\n",
        "  net.save_state_on_file(f'magic_ep_{epoch+1}_acc_{valid_value_s}_time_{time_ep}.pth')\n",
        "  torch.save({ 'optimizer' : optimizer.state_dict()}, f'optimizer_ep_{epoch+1}.pth.tar')\n",
        "  write_list(loss_syn_c_file, p_myloss_clas_syn)\n",
        "  write_list(loss_syn_p_file, p_myloss_pretext_syn)\n",
        "  write_list(loss_rod_c_file, p_myloss_clas_rod)\n",
        "  write_list(loss_rod_p_file, p_myloss_pretext_rod)\n",
        "  write_list(validations_file, [valid_value])\n",
        "  p_myloss_clas_syn = []\n",
        "  p_myloss_pretext_syn = []\n",
        "  p_myloss_clas_rod = []\n",
        "  p_myloss_pretext_rod = []\n",
        "  if stop_trining_4(p_validations):\n",
        "    effective_ep = epoch + 1\n",
        "    print(f'Accuracy scores are degenerating for four consecuive epochs at epoch:{effective_ep}')\n",
        "    break  \n",
        "and_get_advice = time.time() \n",
        "if effective_ep == -1: \n",
        "  effective_ep = NUM_EPOCHS\n",
        "getTimes(ask_for_money, and_get_advice, f'{effective_ep} EPOCHS')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0GL4cRDtr1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_myloss_clas_rod = read_list(loss_rod_c_file)\n",
        "p_myloss_clas_syn = read_list(loss_syn_c_file)\n",
        "p_myloss_pretext_rod = read_list(loss_rod_p_file)\n",
        "p_myloss_pretext_syn = read_list(loss_syn_p_file)\n",
        "plot_losses([p_myloss_clas_syn, p_myloss_clas_rod, p_myloss_pretext_syn, p_myloss_pretext_rod],\n",
        "            labels=['Loss synROD Classification','Loss ROD Entropy', 'Loss synROD Pretext', 'Loss ROD Pretext'], sampling_size=30,\n",
        "            legend_pos=(0.68,0.99))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuQKigy0kenz",
        "colab_type": "text"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szDQ1G2H4o7t",
        "colab": {}
      },
      "source": [
        "ROD_dataset.set_validation(True)\n",
        "p_test_value = test_validate(p_best_net, ROD_dataloader, len(ROD_dataset), DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rPHh51_54o71",
        "colab": {}
      },
      "source": [
        "plot_accuracies(p_validations, p_test_value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSvuf22oD8f3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print same summary\n",
        "steps_per_epochs = int(len(synROD_reduced_dataset) / BATCH_SIZE)\n",
        "argmax_v = np.argmax(p_validations) + 1\n",
        "best_step = steps_per_epochs*argmax_v - 1\n",
        "b_syn_c = p_myloss_clas_syn[best_step]\n",
        "b_rod_c = p_myloss_clas_rod[best_step]\n",
        "b_syn_p = p_myloss_pretext_syn[best_step]\n",
        "b_rod_p = p_myloss_pretext_rod[best_step]\n",
        "print(f'-------------------- Data for x -------------------')\n",
        "print(f'|{\"Test Acc\":8}|{\"Best Validation\":15}|{\"Best Epoch\":10}|{\"Total Epochs\":12}|')\n",
        "print(f'|{p_test_value:8.5f}|{p_validations[argmax_v]:15.5f}|{argmax_v:10}|{effective_ep:12}|')\n",
        "print(f'-------------------------.-------------------------')\n",
        "print(f'-----------------STEP {p_current_step:6}-----------------')\n",
        "print(f'|{\"SYN CLASS\":10}|{\"ROD CLASS\":10}|{\"PRE S\":10}|{\"PRE T\":10}|')\n",
        "print(f'|{b_syn_c:10.4f}|{b_rod_c:10.4f}|{b_syn_p:10.4f}|{b_rod_p:10.4f}|')\n",
        "print(f'---------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}